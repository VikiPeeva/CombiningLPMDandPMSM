{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import Popen\n",
    "\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import silhouette_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T05:20:14.522820700Z",
     "start_time": "2023-06-15T05:20:13.815498500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "lpms_directory = os.path.abspath(\"./data/lpms\") # this is the directory that includes the sets of local process models\n",
    "scripts_directory = os.path.abspath(\"./scripts/clustering\")\n",
    "\n",
    "res_directory = os.path.abspath(\"results\") # this it the directory where results will be outputted"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T05:03:46.821200Z",
     "start_time": "2023-06-15T05:03:46.802911100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hierarchical clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\scripts\\clustering\\clustering_one.py efg_distances C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\results\\artificialBig\\distances\\model_efg_distances.csv C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\results\\artificialBig\\clustering\n",
      "python C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\scripts\\clustering\\clustering_one.py full_trace_matching_distances C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\results\\artificialBig\\distances\\model_full_trace_matching_distances.csv C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\results\\artificialBig\\clustering\n",
      "python C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\scripts\\clustering\\clustering_one.py ged_distances C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\results\\artificialBig\\distances\\model_ged_distances.csv C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\results\\artificialBig\\clustering\n",
      "python C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\scripts\\clustering\\clustering_one.py node_distances C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\results\\artificialBig\\distances\\model_node_distances.csv C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\results\\artificialBig\\clustering\n",
      "python C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\scripts\\clustering\\clustering_one.py transition_label_distances C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\results\\artificialBig\\distances\\model_transition_label_distances.csv C:\\Users\\peeva\\My\\code\\my\\CombiningLPMDandPMSM\\results\\artificialBig\\clustering\n"
     ]
    }
   ],
   "source": [
    "# cluster\n",
    "cl_processes = []\n",
    "for lpm_set_name in os.listdir(lpms_directory):\n",
    "    distances_dir = os.path.join(res_directory, lpm_set_name, \"distances\")\n",
    "    clustering_dir = os.path.join(res_directory, lpm_set_name, \"clustering\")\n",
    "    if not os.path.exists(clustering_dir):\n",
    "        os.mkdir(clustering_dir)\n",
    "    for file in os.listdir(distances_dir):\n",
    "        match_measure = re.search('model_(.*).csv', os.path.basename(file))\n",
    "        if match_measure is not None:\n",
    "            measure = match_measure.group(1)\n",
    "            cl_processes.append(Popen([\"python\", os.path.join(scripts_directory, \"clustering_one.py\"), measure, os.path.join(distances_dir, file), clustering_dir]))\n",
    "\n",
    "try:\n",
    "    exitcodes = [p.wait() for p in cl_processes]\n",
    "    if not all(el == 0 for el in exitcodes):\n",
    "        print(\"Some clustering scripts did not finish successfully: \" + str(exitcodes))\n",
    "except KeyboardInterrupt:\n",
    "    [p.kill() for p in cl_processes]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T05:03:50.307191300Z",
     "start_time": "2023-06-15T05:03:47.661353400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate Silhouette Scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "measures = {\n",
    "    \"efg\": \"efg\",\n",
    "    \"full_trace_matching\": \"full\",\n",
    "    \"ged\": \"ged\",\n",
    "    \"node\": \"node\",\n",
    "    \"transition_label\": \"transition\"\n",
    "}\n",
    "inv_measures = {v: k for k, v in measures.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T05:23:40.898667400Z",
     "start_time": "2023-06-15T05:23:40.890668Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# calculate silhouette scores\n",
    "cl_res_df = pd.DataFrame(columns=[\"Event Log\", \"Distance Threshold\", \"Measure\", \"Num Clusters\"] + list(\n",
    "    measures.values()))  # create main clustering dataframe\n",
    "\n",
    "for f_log in os.listdir(res_directory):\n",
    "    # import distances for all measure pairs\n",
    "    distances = {}\n",
    "    distances_dir = os.path.join(res_directory, f_log, \"distances\")\n",
    "    for f_dist in os.listdir(distances_dir):\n",
    "        if f_dist.endswith(\"distances.csv\"):\n",
    "            match_measure = re.search('model_(.*)_distances.csv', os.path.basename(f_dist))\n",
    "            if match_measure is not None:\n",
    "                measure = match_measure.group(1)\n",
    "                dist_df = pd.read_csv(os.path.join(distances_dir, f_dist), index_col=0).fillna(1)\n",
    "                np_dist = dist_df.to_numpy()\n",
    "\n",
    "                distances[(f_log, measure)] = np_dist\n",
    "\n",
    "    clustering_dir = os.path.join(res_directory, f_log, \"clustering\")\n",
    "\n",
    "    for f2 in os.listdir(clustering_dir):\n",
    "        key = tuple(re.split(\"_\", re.search(\"clustering_hierarchical_(.*)_distances.csv\", f2).groups()[0]))\n",
    "\n",
    "        # read clustering results\n",
    "        cl_res = os.path.join(clustering_dir, f2)\n",
    "        cl_df = pd.read_csv(os.path.abspath(cl_res), index_col=0)\n",
    "        if cl_df[\"Labels\"].nunique() < 2 or cl_df[\"Labels\"].nunique() >= len(cl_df):\n",
    "            continue # silhouette score can not be calculated\n",
    "\n",
    "        num_clusters = len(cl_df[\"Labels\"].unique())\n",
    "        distance_threshold = key[1]\n",
    "        measure = key[2]\n",
    "        log = f_log\n",
    "\n",
    "        # calculate silhouette scores\n",
    "        ss_scores = []\n",
    "        for ss_measure in measures:\n",
    "            ss = silhouette_score(distances[(log, ss_measure)], cl_df[\"Labels\"], metric=\"precomputed\")\n",
    "            ss_scores.append(ss)\n",
    "\n",
    "        # append result to final df\n",
    "        cl_res_df.loc[len(cl_res_df)] = [log, distance_threshold, measure, num_clusters] + ss_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T05:25:20.926430500Z",
     "start_time": "2023-06-15T05:25:20.075072100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# save complete silhouette scores\n",
    "\n",
    "ss_dir = os.path.join(res_directory, \"ss\")\n",
    "if not os.path.exists(ss_dir):\n",
    "    os.mkdir(ss_dir)\n",
    "cl_res_df.to_csv(os.path.join(ss_dir, \"complete_ss.csv\"), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T05:25:40.630334900Z",
     "start_time": "2023-06-15T05:25:40.610335700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
